"""
TaskExecutor: Task execution specialist for the core layer.

This component manages task execution, dependency resolution, and parallel processing.
"""

import asyncio
import logging
from typing import List, Dict, Any, Set, Optional
from .models import Task, TaskStatus, TaskChainManager, ExecutionResult
from .exceptions import TaskExecutionError, CircularDependencyError, AmbiguityDetected
from .service_coordinator import ServiceCoordinator
from config.loggers import GenericLogger


class TaskExecutor:
    """Executes tasks with dependency resolution and parallel processing."""
    
    def __init__(self, service_coordinator: ServiceCoordinator, confirmation_service=None):
        self.service_coordinator = service_coordinator
        self.confirmation_service = confirmation_service
        self.logger = GenericLogger("core", "executor")
    
    async def execute(self, tasks: List[Task], user_id: str, task_chain_manager: TaskChainManager, token: str) -> ExecutionResult:
        """
        Execute a list of tasks with dependency resolution.
        
        Args:
            tasks: List of tasks to execute
            user_id: User identifier
            task_chain_manager: Task chain manager for progress tracking
            token: Authentication token
            
        Returns:
            ExecutionResult with status and outputs
        """
        try:
            self.logger.info(f"ğŸ”„ [EXECUTOR] Starting ReAct loop with {len(tasks)} tasks for user {user_id}")
            
            # ã€æ–°è¦è¿½åŠ ã€‘å®Ÿè¡Œå‰ã«æ›–æ˜§æ€§ãƒã‚§ãƒƒã‚¯
            if self.confirmation_service:
                self.logger.info(f"ğŸ” [EXECUTOR] Checking for ambiguity before execution")
                
                # ConfirmationServiceã§æ›–æ˜§æ€§ãƒã‚§ãƒƒã‚¯
                ambiguity_result = await self.confirmation_service.detect_ambiguity(tasks, user_id, token)
                
                if ambiguity_result.requires_confirmation:
                    self.logger.info(f"âš ï¸ [EXECUTOR] Ambiguity detected, requesting confirmation")
                    
                    # æœ€åˆã®æ›–æ˜§ãªã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’å–å¾—
                    first_ambiguous_task = ambiguity_result.ambiguous_tasks[0]
                    
                    return ExecutionResult(
                        status="needs_confirmation",
                        confirmation_context={
                            "ambiguity_info": first_ambiguous_task,
                            "user_response": "",
                            "original_tasks": tasks
                        },
                        outputs={},
                        message=first_ambiguous_task.details["message"]
                    )
                
                self.logger.info(f"âœ… [EXECUTOR] No ambiguity detected, proceeding with execution")
            
            # Log task dependency graph
            self.logger.info(f"ğŸ“Š [EXECUTOR] Task dependency graph:")
            for task in tasks:
                deps_str = f"deps: {task.dependencies}" if task.dependencies else "no dependencies"
                self.logger.info(f"  - {task.id}: {task.service}.{task.method} ({deps_str})")
            
            remaining_tasks = tasks.copy()
            all_results = {}
            iteration = 0
            
            while remaining_tasks:
                iteration += 1
                self.logger.info(f"ğŸ”„ [EXECUTOR] ReAct iteration {iteration}: {len(remaining_tasks)} tasks remaining")
                # Find executable group (tasks with resolved dependencies)
                executable_group = self._find_executable_group(remaining_tasks, all_results)
                
                if not executable_group:
                    # Check if we have remaining tasks but no executable ones
                    if remaining_tasks:
                        self.logger.error(f"âŒ [EXECUTOR] Circular dependency detected in task graph")
                        raise CircularDependencyError("Circular dependency detected in task graph")
                    self.logger.info(f"âœ… [EXECUTOR] All tasks completed")
                    break
                
                # Log executable group
                group_task_ids = [task.id for task in executable_group]
                self.logger.info(f"âš¡ [EXECUTOR] Executing group {iteration}: {group_task_ids}")
                for task in executable_group:
                    self.logger.info(f"  - {task.id}: {task.service}.{task.method}")
                
                # Execute tasks in parallel
                group_results = await self._execute_group(executable_group, user_id, all_results, task_chain_manager, token)
                
                # Process results
                completed_count = 0
                for task, result in zip(executable_group, group_results):
                    if isinstance(result, AmbiguityDetected):
                        # Ambiguity detected - interrupt execution
                        self.logger.warning(f"âš ï¸ [EXECUTOR] Ambiguity detected in task {task.id}: {result.message}")
                        return ExecutionResult(
                            status="needs_confirmation",
                            confirmation_context=result.context,
                            message=result.message
                        )
                    
                    if isinstance(result, Exception):
                        self.logger.error(f"âŒ [EXECUTOR] Task {task.id} failed: {str(result)}")
                        task.status = TaskStatus.FAILED
                        task.error = str(result)
                        task_chain_manager.update_task_status(task.id, TaskStatus.FAILED, error=str(result))
                    else:
                        self.logger.info(f"âœ… [EXECUTOR] Task {task.id} completed successfully")
                        task.status = TaskStatus.COMPLETED
                        task.result = result
                        all_results[task.id] = result
                        task_chain_manager.update_task_status(task.id, TaskStatus.COMPLETED, result)
                        completed_count += 1
                
                # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯æ•°åˆ†ã ã‘é€²æ—ã‚’æ›´æ–°
                if completed_count > 0:
                    task_chain_manager.current_step += completed_count
                    
                    # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’ä½¿ç”¨
                    completed_tasks = [task for task, result in zip(executable_group, group_results) 
                                     if not isinstance(result, Exception) and not isinstance(result, AmbiguityDetected)]
                    
                    if completed_tasks:
                        # æœ€åˆã®å®Œäº†ã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’ä½¿ç”¨
                        first_completed_task = completed_tasks[0]
                        task_chain_manager.send_progress(first_completed_task.id, "å®Œäº†", f"{completed_count}å€‹ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ")
                
                # Remove completed tasks from remaining
                completed_ids = [task.id for task in executable_group]
                remaining_tasks = [t for t in remaining_tasks if t.id not in completed_ids]
                self.logger.info(f"ğŸ“Š [EXECUTOR] Completed {len(completed_ids)} tasks, {len(remaining_tasks)} remaining")
            
            self.logger.info("âœ… [EXECUTOR] ReAct loop completed successfully")
            return ExecutionResult(status="success", outputs=all_results)
            
        except AmbiguityDetected as e:
            return ExecutionResult(
                status="needs_confirmation",
                confirmation_context=e.context,
                message=e.message
            )
        except Exception as e:
            self.logger.error(f"Task execution failed: {str(e)}")
            return ExecutionResult(status="error", message=str(e))
    
    def _find_executable_group(self, tasks: List[Task], completed_results: Dict[str, Any]) -> List[Task]:
        """Find tasks that can be executed (dependencies resolved)."""
        executable = []
        
        for task in tasks:
            if task.status != TaskStatus.PENDING:
                continue
                
            # Check if all dependencies are completed
            if self._are_dependencies_satisfied(task, completed_results):
                executable.append(task)
        
        return executable
    
    def _are_dependencies_satisfied(self, task: Task, completed_results: Dict[str, Any]) -> bool:
        """Check if all task dependencies are satisfied."""
        for dep_id in task.dependencies:
            if dep_id not in completed_results:
                return False
        return True
    
    async def _execute_group(self, tasks: List[Task], user_id: str, previous_results: Dict[str, Any], task_chain_manager: TaskChainManager, token: str) -> List[Any]:
        """Execute a group of tasks in parallel."""
        coroutines = []
        
        for task in tasks:
            task.status = TaskStatus.RUNNING
            task_chain_manager.update_task_status(task.id, TaskStatus.RUNNING)
            
            coroutine = self._execute_single_task(task, user_id, previous_results, token, task_chain_manager)
            coroutines.append(coroutine)
        
        # Execute all tasks in parallel
        results = await asyncio.gather(*coroutines, return_exceptions=True)
        return results
    
    async def _execute_single_task(self, task: Task, user_id: str, previous_results: Dict[str, Any], token: str, task_chain_manager: TaskChainManager = None) -> Any:
        """Execute a single task with data injection."""
        try:
            self.logger.info(f"ğŸš€ [EXECUTOR] Starting task {task.id}: {task.service}.{task.method}")
            
            # Inject data from previous tasks
            injected_params = self._inject_data(task.parameters, previous_results)
            
            # Phase 1F: session_get_proposed_titlesã®sse_session_idã‚’å®Ÿéš›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã§ç½®ãæ›ãˆ
            if task.method == "session_get_proposed_titles" and task_chain_manager and task_chain_manager.sse_session_id:
                # ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãŒç”Ÿæˆã—ãŸå›ºå®šå€¤ï¼ˆä¾‹: "session123"ï¼‰ã‚’å®Ÿéš›ã®sse_session_idã§ç½®ãæ›ãˆ
                if "sse_session_id" in injected_params:
                    old_value = injected_params["sse_session_id"]
                    injected_params["sse_session_id"] = task_chain_manager.sse_session_id
                    self.logger.info(f"ğŸ”„ [EXECUTOR] Replaced sse_session_id: '{old_value}' â†’ '{task_chain_manager.sse_session_id}'")
            
            self.logger.info(f"ğŸ“¥ [EXECUTOR] Task {task.id} input parameters: {injected_params}")
            
            # Execute service method with token
            # Phase 3A: sse_session_idã‚’parametersã«è¿½åŠ ï¼ˆgenerate_proposalsã®ã¿ï¼‰
            if task_chain_manager and task_chain_manager.sse_session_id and task.method == "generate_proposals":
                injected_params["sse_session_id"] = task_chain_manager.sse_session_id
            
            result = await self.service_coordinator.execute_service(
                task.service, task.method, injected_params, token
            )
            
            self.logger.info(f"ğŸ“¤ [EXECUTOR] Task {task.id} output result: {result}")
            self.logger.info(f"âœ… [EXECUTOR] Task {task.id} completed successfully")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ [EXECUTOR] Task {task.id} failed: {str(e)}")
            raise
    
    def _inject_data(self, parameters: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """Inject data from previous task results into parameters (è¾æ›¸æ§‹é€ å¯¾å¿œç‰ˆ)."""
        injected = parameters.copy()
        
        
        for key, value in parameters.items():
            self.logger.info(f"ğŸ” [EXECUTOR] Processing parameter: key={key}, value={value}, type={type(value)}")
            
            # Phase 1F: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‚ç…§ã®å‡¦ç†ï¼ˆ"session.context.xxx"å½¢å¼ï¼‰
            if isinstance(value, str) and value.startswith("session.context."):
                self.logger.info(f"ğŸ” [EXECUTOR] Detected session context reference: {value}")
                # ã“ã®æ™‚ç‚¹ã§ã¯æ–‡å­—åˆ—ã®ã¾ã¾ä¿æŒï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§å®Ÿéš›ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å–å¾—ã™ã‚‹ï¼‰
                # injected[key] = value  # æ—¢ã«valueãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚å¤‰æ›´ä¸è¦
                continue
            
            if isinstance(value, str):
                # çµåˆæ¼”ç®—: "task1.result.data + task2.result.data"
                if " + " in value and ".result." in value:
                    self.logger.info(f"ğŸ” [EXECUTOR] Match: concatenation operation ({value})")
                    resolved_value = self._resolve_concatenation(value, previous_results)
                    if resolved_value is not None:
                        injected[key] = resolved_value
                        self.logger.info(f"ğŸ”— [EXECUTOR] Resolved concatenation '{value}' = {len(resolved_value)} items")
                
                # è¾æ›¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§: "task2.result.main_dish"
                elif ".result." in value and value.endswith((".main_dish", ".side_dish", ".soup")):
                    self.logger.info(f"ğŸ” [EXECUTOR] Match: dict field reference ({value})")
                    field_value = self._extract_field_from_result(value, previous_results)
                    injected[key] = field_value
                    self.logger.info(f"ğŸ”— [EXECUTOR] Extracted field '{value}' = '{field_value}'")
                
                # è¤‡æ•°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§: "task2.result.main_dish,task3.result.main_dish"
                elif "," in value and ".result." in value:
                    self.logger.info(f"ğŸ” [EXECUTOR] Match: multiple fields reference ({value})")
                    field_values = self._extract_multiple_fields(value, previous_results)
                    injected[key] = field_values
                    self.logger.info(f"ğŸ”— [EXECUTOR] Extracted multiple fields '{value}' = {field_values}")
                
                # ãƒã‚¹ãƒˆãƒ‘ã‚¹å‚ç…§: "task2.result.data", "task1.result.success" ãªã©
                elif ".result." in value:
                    self.logger.info(f"ğŸ” [EXECUTOR] Match: nested path reference ({value})")
                    resolved_value = self._extract_nested_path(value, previous_results)
                    if resolved_value is not None:
                        injected[key] = resolved_value
                        self.logger.info(f"ğŸ”— [EXECUTOR] Injected nested path '{value}' = {resolved_value}")
                
                # å˜ä¸€ã‚¿ã‚¹ã‚¯çµæœå‚ç…§: "task1.result"
                elif value.endswith(".result"):
                    self.logger.info(f"ğŸ” [EXECUTOR] Match: single task result reference ({value})")
                    task_ref = value[:-7]  # "task1.result" -> "task1"
                    
                    if task_ref in previous_results:
                        # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é£Ÿæåãƒªã‚¹ãƒˆã‚’æŠ½å‡º
                        inventory_data = previous_results[task_ref]
                        
                        if isinstance(inventory_data, dict) and inventory_data.get("success"):
                            items = inventory_data.get("result", {}).get("data", [])
                            item_names = [item.get("item_name") for item in items if item.get("item_name")]
                            injected[key] = item_names
                            self.logger.info(f"ğŸ”— [EXECUTOR] Injected {len(item_names)} items from {task_ref} to {key}")
                        else:
                            self.logger.warning(f"âš ï¸ [EXECUTOR] Inventory data is not successful: {inventory_data}")
                    else:
                        self.logger.warning(f"âš ï¸ [EXECUTOR] Task reference not found in previous_results: {task_ref}")
                else:
                    self.logger.info(f"ğŸ” [EXECUTOR] No match: keeping original value ({value})")
                    # ãã®ä»–ã®æ–‡å­—åˆ—ã¯ãã®ã¾ã¾ä¿æŒ
                    pass
            
            elif isinstance(value, list):
                # ğŸ†• ãƒªã‚¹ãƒˆå‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‡¦ç†ã‚’è¿½åŠ 
                resolved_list = []
                
                for item in value:
                    if isinstance(item, str):
                        # ãƒªã‚¹ãƒˆå†…ã®å„è¦ç´ ã‚’è§£æ±º
                        if ".result." in item:
                            # ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ã‚¹ï¼ˆtask2.result.data.main_dishãªã©ï¼‰ã®å ´åˆã¯_extract_nested_pathã‚’ä½¿ç”¨
                            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¹ï¼ˆtask2.result.main_dishï¼‰ã®å ´åˆã¯_extract_field_from_resultã‚’ä½¿ç”¨
                            dot_count = item.count(".")
                            if dot_count >= 3 and item.endswith((".main_dish", ".side_dish", ".soup")):
                                # ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ã‚¹ã®å ´åˆ
                                field_value = self._extract_nested_path(item, previous_results)
                                resolved_list.append(field_value if field_value is not None else "")
                                self.logger.info(f"ğŸ”— [EXECUTOR] Resolved nested path list item '{item}' = '{field_value}'")
                            elif item.endswith((".main_dish", ".side_dish", ".soup")):
                                # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¹ã®å ´åˆ
                                field_value = self._extract_field_from_result(item, previous_results)
                                resolved_list.append(field_value)
                                self.logger.info(f"ğŸ”— [EXECUTOR] Resolved list item '{item}' = '{field_value}'")
                            elif item.endswith(".result"):
                                # å˜ä¸€ã‚¿ã‚¹ã‚¯çµæœå‚ç…§
                                task_ref = item[:-7]
                                if task_ref in previous_results:
                                    task_result = previous_results[task_ref]
                                    if isinstance(task_result, dict) and task_result.get("success"):
                                        resolved_list.append(task_result.get("result", {}))
                                        self.logger.info(f"ğŸ”— [EXECUTOR] Resolved list item '{item}' = task result")
                                else:
                                    resolved_list.append(item)
                            else:
                                # ãã®ä»–ã®.result.ã‚’å«ã‚€æ–‡å­—åˆ—ã¯ãƒã‚¹ãƒˆãƒ‘ã‚¹ã¨ã—ã¦å‡¦ç†
                                resolved_value = self._extract_nested_path(item, previous_results)
                                resolved_list.append(resolved_value if resolved_value is not None else item)
                                self.logger.info(f"ğŸ”— [EXECUTOR] Resolved nested path list item '{item}' = '{resolved_value}'")
                        else:
                            # ãã®ä»–ã®æ–‡å­—åˆ—ã¯ãã®ã¾ã¾
                            resolved_list.append(item)
                    else:
                        # æ–‡å­—åˆ—ä»¥å¤–ã¯ãã®ã¾ã¾
                        resolved_list.append(item)
                
                injected[key] = resolved_list
                self.logger.info(f"ğŸ”— [EXECUTOR] Resolved list parameter '{key}' = {resolved_list}")
            
            else:
                # ãã®ä»–ã®å‹ã¯ãã®ã¾ã¾ä¿æŒ
                pass
        
        return injected
    
    def _extract_field_from_result(self, value: str, previous_results: Dict[str, Any]) -> str:
        """è¾æ›¸æ§‹é€ ã‹ã‚‰ç‰¹å®šãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º"""
        # "task2.result.main_dish" -> task2ã®main_dishãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º
        parts = value.split(".")
        task_id = parts[0]
        field_name = parts[2]  # main_dish, side_dish, soup
        
        
        if task_id in previous_results:
            task_result = previous_results[task_id]
            
            if isinstance(task_result, dict) and task_result.get("success"):
                data = task_result.get("result", {}).get("data", {})
                field_value = data.get(field_name, "")
                self.logger.info(f"ğŸ”— [EXECUTOR] Extracted '{field_name}' = '{field_value}'")
                return field_value
            else:
                self.logger.warning(f"âš ï¸ [EXECUTOR] Task result is not successful: {task_result}")
        else:
            self.logger.warning(f"âš ï¸ [EXECUTOR] Task '{task_id}' not found in previous_results")
        
        return ""
    
    def _extract_multiple_fields(self, value: str, previous_results: Dict[str, Any]) -> List[str]:
        """è¤‡æ•°ã®è¾æ›¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆåŒ–"""
        field_refs = [ref.strip() for ref in value.split(",")]
        results = []
        
        
        for field_ref in field_refs:
            if ".result." in field_ref:
                field_value = self._extract_field_from_result(field_ref, previous_results)
                if field_value:  # ç©ºæ–‡å­—åˆ—ã¯é™¤å¤–
                    results.append(field_value)
                    self.logger.info(f"ğŸ”— [EXECUTOR] Added field value: '{field_value}'")
                else:
                    # ç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    pass
        
        self.logger.info(f"ğŸ”— [EXECUTOR] Final extracted values: {results}")
        return results
    
    def _extract_nested_path(self, path: str, previous_results: Dict[str, Any]) -> Any:
        """ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ã‚¹ã‚’è§£æ±ºï¼ˆä»»æ„ã®æ·±ã•ã«å¯¾å¿œ: task2.result.data.candidates ãªã©ï¼‰"""
        parts = path.split(".")
        if len(parts) < 2:
            self.logger.warning(f"âš ï¸ [EXECUTOR] Invalid nested path format: {path}")
            return None
        
        task_id = parts[0]  # "task2"
        path_after_task = parts[1:]  # ["result", "data", "candidates"]
        
        self.logger.info(f"ğŸ” [EXECUTOR] Extracting nested path: {path}")
        self.logger.info(f"ğŸ” [EXECUTOR] task_id={task_id}, nested_path={'.'.join(path_after_task)}")
        
        if task_id not in previous_results:
            self.logger.warning(f"âš ï¸ [EXECUTOR] Task '{task_id}' not found")
            return None
        
        task_result = previous_results[task_id]
        
        # å†å¸°çš„ã«ãƒ‘ã‚¹ã‚’è¾¿ã‚‹
        current_value = task_result
        
        for key in path_after_task:
            if isinstance(current_value, dict):
                if key in current_value:
                    current_value = current_value[key]
                    self.logger.info(f"ğŸ”— [EXECUTOR] Traversing to '{key}': found {type(current_value).__name__}")
                else:
                    self.logger.warning(f"âš ï¸ [EXECUTOR] Key '{key}' not found in {list(current_value.keys())}")
                    return None
            else:
                self.logger.warning(f"âš ï¸ [EXECUTOR] Cannot traverse '{key}' from {type(current_value).__name__}")
                return None
        
        self.logger.info(f"âœ… [EXECUTOR] Successfully extracted: {type(current_value).__name__}")
        
        # Phase 3A Fix: candidatesãŒè¾æ›¸ã®ãƒªã‚¹ãƒˆã®å ´åˆã€titleã®ãƒªã‚¹ãƒˆã«å¤‰æ›
        if isinstance(current_value, list) and len(current_value) > 0 and isinstance(current_value[0], dict):
            if "title" in current_value[0]:
                titles = [item["title"] for item in current_value if "title" in item]
                self.logger.info(f"ğŸ”§ [EXECUTOR] Converted candidates list to title list: {len(titles)} titles")
                return titles
        
        return current_value
    
    def _resolve_concatenation(self, expression: str, previous_results: Dict[str, Any]) -> Optional[list]:
        """çµåˆæ¼”ç®—ã‚’è§£æ±ºï¼ˆä¾‹: "task1.result.data + task2.result.data"ï¼‰"""
        try:
            parts = expression.split(" + ")
            result_list = []
            
            for part in parts:
                part = part.strip()
                # ãƒã‚¹ãƒˆãƒ‘ã‚¹å‚ç…§ã¨ã—ã¦è§£æ±º
                resolved_value = self._extract_nested_path(part, previous_results)
                
                if resolved_value is not None:
                    # ãƒªã‚¹ãƒˆã®å ´åˆã¯æ‹¡å¼µã€ãã‚Œä»¥å¤–ã¯è¿½åŠ 
                    if isinstance(resolved_value, list):
                        result_list.extend(resolved_value)
                        self.logger.info(f"ğŸ”— [EXECUTOR] Extended {len(resolved_value)} items from {part}")
                    else:
                        result_list.append(resolved_value)
                        self.logger.info(f"ğŸ”— [EXECUTOR] Added item from {part}")
                else:
                    self.logger.warning(f"âš ï¸ [EXECUTOR] Could not resolve part: {part}")
            
            self.logger.info(f"âœ… [EXECUTOR] Concatenation result: {len(result_list)} items")
            return result_list
            
        except Exception as e:
            self.logger.error(f"âŒ [EXECUTOR] Error in _resolve_concatenation: {e}")
            return None
